#!/usr/bin/env python3
"""
Generate Markdown report from JSON analysis results
"""
import json
import sys
from datetime import datetime


def _dedupe_keep_order(values):
    seen = set()
    output = []
    for value in values:
        if value in seen:
            continue
        seen.add(value)
        output.append(value)
    return output


def generate_markdown_report(data):
    """Generate a comprehensive Markdown report from analysis data"""

    md = []
    result = data.get('siteResult') if data.get('mode') == 'site' else data.get('result')
    optimization = data.get('siteOptimization') if data.get('mode') == 'site' else data.get('optimization')
    optimization_summary = optimization.get('summary', {}) if optimization else {}
    critical_count = optimization_summary.get('critical', 0)
    warning_count = optimization_summary.get('warnings', 0)

    # Header
    md.append("# ç½‘ç«™åˆ†ææŠ¥å‘Š\n")
    md.append(f"**åˆ†ææ—¶é—´**: {data.get('analyzedAt', 'N/A')}\n")
    md.append(f"**åˆ†ææ¨¡å¼**: {'å¤šé¡µé¢ç«™ç‚¹åˆ†æ' if data.get('mode') == 'site' else 'å•é¡µé¢åˆ†æ'}\n")
    md.append(f"**ç›®æ ‡ç½‘ç«™**: {data.get('url', 'N/A')}\n")

    # Executive summary
    md.append("\n## ğŸ§­ æ‰§è¡Œæ‘˜è¦\n")
    if result:
        confidence = result.get('regionConfidence', 0)
        md.append(f"- ç›®æ ‡åœ°åŒºï¼š**{result.get('primaryRegionName', 'Unknown')}**ï¼ˆ{result.get('primaryRegion', 'N/A')}ï¼‰\n")
        md.append(f"- ä¸»è¦è¯­è¨€ï¼š**{result.get('primaryLanguageName', 'Unknown')}**ï¼ˆ{result.get('primaryLanguage', 'N/A')}ï¼‰\n")
        md.append(f"- ç›®æ ‡å—ä¼—ï¼š**{result.get('likelyAudience', 'N/A')}**\n")
        md.append(f"- åœ°åŒºç½®ä¿¡åº¦ï¼š**{confidence:.2f}**\n")
    else:
        md.append("- æš‚æ— å¯ç”¨çš„åœ°åŒºä¸å—ä¼—ç»“è®ºã€‚\n")

    if optimization:
        score = optimization_summary.get('score', 0)
        grade = optimization_summary.get('grade', 'N/A')
        md.append(f"- æœ¬åœ°åŒ–è¯„åˆ†ï¼š**{score}/100ï¼ˆ{grade}ï¼‰**\n")
        md.append(f"- é—®é¢˜æ¦‚è§ˆï¼šå…³é”®é—®é¢˜ **{critical_count}** é¡¹ï¼Œè­¦å‘Š **{warning_count}** é¡¹\n")
    else:
        md.append("- æš‚æ— æœ¬åœ°åŒ–ä¼˜åŒ–è¯„åˆ†æ•°æ®ã€‚\n")

    # Crawl Summary (if site mode)
    if data.get('mode') == 'site' and data.get('crawlSummary'):
        summary = data['crawlSummary']
        md.append("\n## ğŸ“Š çˆ¬å–æ‘˜è¦\n")
        md.append(f"- **åˆ†æé¡µé¢æ•°**: {summary.get('pagesAnalyzed', 0)}\n")
        md.append(f"- **æœ€å¤§çˆ¬å–æ·±åº¦**: {summary.get('maxDepthReached', 0)}\n")
        md.append(f"- **é¡µé¢åˆ—è¡¨**:\n")
        for url in summary.get('pageUrls', [])[:10]:  # Show first 10
            md.append(f"  - {url}\n")
        if len(summary.get('pageUrls', [])) > 10:
            md.append(f"  - ... åŠå…¶ä»– {len(summary['pageUrls']) - 10} ä¸ªé¡µé¢\n")

    # Main Results
    if result:
        md.append("\n## ğŸ¯ åœ°åŒºä¸å—ä¼—åˆ†æ\n")
        md.append(f"### ä¸»è¦ç»“è®º\n")
        md.append(f"- **ç›®æ ‡åœ°åŒº**: {result.get('primaryRegionName', 'Unknown')} ({result.get('primaryRegion', 'N/A')})\n")
        md.append(f"- **ä¸»è¦è¯­è¨€**: {result.get('primaryLanguageName', 'Unknown')} ({result.get('primaryLanguage', 'N/A')})\n")
        md.append(f"- **ç›®æ ‡å—ä¼—**: {result.get('likelyAudience', 'N/A')}\n")

        confidence = result.get('regionConfidence', 0)
        confidence_level = "é«˜" if confidence > 0.6 else "ä¸­" if confidence > 0.3 else "ä½"
        confidence_emoji = "ğŸŸ¢" if confidence > 0.6 else "ğŸŸ¡" if confidence > 0.3 else "ğŸ”´"
        md.append(f"- **åœ°åŒºç½®ä¿¡åº¦**: {confidence:.2f} {confidence_emoji} ({confidence_level}ç½®ä¿¡åº¦)\n")

        # Confidence interpretation
        md.append(f"\n### ç½®ä¿¡åº¦è§£è¯»\n")
        if confidence > 0.6:
            md.append("âœ… **é«˜ç½®ä¿¡åº¦** - å¤šä¸ªä¿¡å·ä¸€è‡´æŒ‡å‘åŒä¸€åœ°åŒºï¼Œåˆ¤æ–­å¯é ã€‚\n")
        elif confidence > 0.3:
            md.append("âš ï¸ **ä¸­ç­‰ç½®ä¿¡åº¦** - éƒ¨åˆ†ä¿¡å·ä¸€è‡´ï¼Œä½†å­˜åœ¨ç¼ºå¤±æˆ–å†²çªã€‚\n")
        else:
            md.append("ğŸ”´ **ä½ç½®ä¿¡åº¦** - è¿™é€šå¸¸è¡¨æ˜ç½‘ç«™æ˜¯å…¨çƒåŒ–ç«™ç‚¹ï¼Œç¼ºä¹æ˜ç¡®çš„åœ°åŒºä¿¡å·ã€‚å¯¹äºè·¨å¢ƒç”µå•†æ¥è¯´è¿™æ˜¯æ­£å¸¸çš„ã€‚\n")

    # Evidence Analysis
    if data.get('mode') == 'site':
        # For site mode, use first page's evidence as example
        evidence = data.get('pages', [{}])[0].get('evidence', {})
    else:
        evidence = data.get('evidence', {})

    if evidence:
        md.append("\n## ğŸ” ä¿¡å·åˆ†æ\n")

        # HTML Signals
        html_signals = evidence.get('htmlSignals', {})
        if html_signals:
            md.append("### HTML å…ƒæ•°æ®ä¿¡å·\n")
            md.append(f"- **è¯­è¨€å£°æ˜**: `<html lang=\"{html_signals.get('lang', 'N/A')}\">`\n")
            md.append(f"- **å­—ç¬¦é›†**: {html_signals.get('charset', 'N/A')}\n")
            md.append(f"- **og:locale**: {html_signals.get('metaLocale') or 'âŒ æœªè®¾ç½®'}\n")
            md.append(f"- **content-language**: {html_signals.get('metaLanguage') or 'âŒ æœªè®¾ç½®'}\n")
            md.append(f"- **hreflang æ ‡ç­¾**: {len(html_signals.get('hreflangTags', [])) or 'âŒ æœªè®¾ç½®'}\n")
            md.append(f"- **é¡¶çº§åŸŸå**: {html_signals.get('tld') or '.com (é€šç”¨)'}\n")

        # Content Signals
        content_signals = evidence.get('contentSignals', {})
        if content_signals:
            md.append("\n### å†…å®¹ä¿¡å·\n")
            currencies = _dedupe_keep_order(
                content_signals.get('currencySymbols', []) + content_signals.get('currencyCodes', [])
            )
            if currencies:
                md.append(f"- **è´§å¸**: {', '.join(currencies)}\n")
            else:
                md.append(f"- **è´§å¸**: æœªæ£€æµ‹åˆ°\n")

            phones = _dedupe_keep_order(content_signals.get('phoneFormats', []))
            if phones:
                md.append(f"- **ç”µè¯æ ¼å¼**: {', '.join(phones)}\n")

            payments = content_signals.get('paymentMethods', [])
            if payments:
                payment_methods = _dedupe_keep_order([p.get('method', 'N/A') for p in payments])
                md.append(f"- **æ”¯ä»˜æ–¹å¼**: {', '.join(payment_methods)}\n")

            social = content_signals.get('socialMediaSignals', [])
            if social:
                social_domains = _dedupe_keep_order([s.get('domain', 'N/A') for s in social])
                md.append(f"- **ç¤¾äº¤åª’ä½“**: {', '.join(social_domains)}\n")

            spelling = content_signals.get('spellingCounts', {})
            if spelling:
                us_count = spelling.get('US', 0)
                uk_count = spelling.get('UK', 0)
                if us_count > uk_count:
                    md.append(f"- **æ‹¼å†™ä¹ æƒ¯**: ç¾å¼è‹±è¯­ ({us_count} å¤„)\n")
                elif uk_count > us_count:
                    md.append(f"- **æ‹¼å†™ä¹ æƒ¯**: è‹±å¼è‹±è¯­ ({uk_count} å¤„)\n")

        # IP Geolocation
        ip_geo = evidence.get('ipGeolocation', {})
        if ip_geo and ip_geo.get('status') == 'success':
            md.append("\n### æœåŠ¡å™¨ä¿¡æ¯\n")
            md.append(f"- **æœåŠ¡å™¨ä½ç½®**: {ip_geo.get('city', 'N/A')}, {ip_geo.get('country', 'N/A')}\n")
            md.append(f"- **ISP**: {ip_geo.get('isp', 'N/A')}\n")
            md.append(f"- **ç»„ç»‡**: {ip_geo.get('org', 'N/A')}\n")

            # CDN detection
            isp = ip_geo.get('isp', '').lower()
            org = ip_geo.get('org', '').lower()
            if any(cdn in isp or cdn in org for cdn in ['cloudflare', 'akamai', 'fastly', 'cloudfront']):
                md.append(f"- **CDN**: âœ… å·²æ£€æµ‹åˆ° CDNï¼ˆå…¨çƒåˆ†å‘ï¼‰\n")

    # Optimization Report
    if optimization:
        md.append("\n## ğŸ“ˆ æœ¬åœ°åŒ–ä¼˜åŒ–è¯„åˆ†\n")

        score = optimization_summary.get('score', 0)
        grade = optimization_summary.get('grade', 'N/A')

        # Grade emoji
        grade_emoji = {
            'A': 'ğŸŸ¢', 'B': 'ğŸŸ¡', 'C': 'ğŸŸ ', 'D': 'ğŸ”´', 'F': 'âš«'
        }.get(grade, 'âšª')

        md.append(f"### æ€»ä½“è¯„åˆ†\n")
        md.append(f"- **åˆ†æ•°**: {score}/100\n")
        md.append(f"- **ç­‰çº§**: {grade_emoji} {grade}\n")
        md.append(f"- **é—®é¢˜æ€»æ•°**: {optimization_summary.get('totalIssues', 0)}\n")
        md.append(f"  - ğŸ”´ å…³é”®é—®é¢˜: {critical_count}\n")
        md.append(f"  - ğŸŸ¡ è­¦å‘Š: {warning_count}\n")
        md.append(f"  - ğŸ”µ ä¿¡æ¯: {optimization_summary.get('info', 0)}\n")

        # Grade interpretation
        md.append(f"\n### è¯„åˆ†è§£è¯»\n")
        if score >= 80:
            md.append("âœ… **ä¼˜ç§€** - æœ¬åœ°åŒ–é…ç½®å®Œå–„ï¼Œä»…æœ‰å°‘é‡éå…³é”®å»ºè®®ã€‚\n")
        elif score >= 60:
            md.append("ğŸŸ¡ **è‰¯å¥½** - åŸºæœ¬é…ç½®åˆ°ä½ï¼Œå­˜åœ¨ä¸€äº›è­¦å‘Šé¡¹éœ€è¦æ”¹è¿›ã€‚\n")
        elif score >= 40:
            md.append("ğŸŸ  **åŠæ ¼** - å­˜åœ¨è¾ƒå¤šé—®é¢˜ï¼Œå»ºè®®ä¼˜å…ˆä¿®å¤å…³é”®é—®é¢˜ã€‚\n")
        elif score >= 20:
            md.append("ğŸ”´ **è¾ƒå·®** - å­˜åœ¨å…³é”®ç¼ºå¤±ï¼Œä¸¥é‡å½±å“å›½é™…åŒ–æ•ˆæœã€‚\n")
        else:
            md.append("âš« **æå·®** - åŸºæœ¬æœªåšæœ¬åœ°åŒ–é…ç½®ï¼Œéœ€è¦å…¨é¢æ”¹è¿›ã€‚\n")

        # Recommendations
        recommendations = optimization.get('recommendations', [])
        if recommendations:
            md.append("\n## ğŸš¨ ä¼˜åŒ–å»ºè®®\n")

            # Group by severity
            critical = [r for r in recommendations if r.get('severity') == 'critical']
            warnings = [r for r in recommendations if r.get('severity') == 'warning']
            info = [r for r in recommendations if r.get('severity') == 'info']

            if critical:
                md.append("\n### ğŸ”´ å…³é”®é—®é¢˜ï¼ˆå¿…é¡»ä¿®å¤ï¼‰\n")
                for i, rec in enumerate(critical, 1):
                    md.append(f"\n#### {i}. {rec.get('category', 'N/A')}\n")
                    md.append(f"**é—®é¢˜**: {rec.get('issue', 'N/A')}\n\n")
                    md.append(f"**å»ºè®®**: {rec.get('recommendation', 'N/A')}\n\n")
                    if rec.get('codeExample'):
                        md.append(f"**ä»£ç ç¤ºä¾‹**:\n```html\n{rec['codeExample']}\n```\n")

            if warnings:
                md.append("\n### ğŸŸ¡ è­¦å‘Šé—®é¢˜ï¼ˆåº”è¯¥ä¿®å¤ï¼‰\n")
                for i, rec in enumerate(warnings, 1):
                    md.append(f"\n#### {i}. {rec.get('category', 'N/A')}\n")
                    md.append(f"**é—®é¢˜**: {rec.get('issue', 'N/A')}\n\n")
                    md.append(f"**å»ºè®®**: {rec.get('recommendation', 'N/A')}\n\n")
                    if rec.get('codeExample'):
                        md.append(f"**ä»£ç ç¤ºä¾‹**:\n```html\n{rec['codeExample']}\n```\n")

            if info:
                md.append("\n### ğŸ”µ ä¿¡æ¯å»ºè®®ï¼ˆå¯é€‰ä¼˜åŒ–ï¼‰\n")
                for i, rec in enumerate(info, 1):
                    md.append(f"\n#### {i}. {rec.get('category', 'N/A')}\n")
                    md.append(f"{rec.get('issue', 'N/A')}\n\n")

    # Next actions
    if optimization:
        md.append("\n## âœ… å»ºè®®ä¼˜å…ˆå¤„ç†\n")
        if critical_count > 0:
            md.append(f"- å½“å‰å­˜åœ¨å…³é”®é—®é¢˜ {critical_count} é¡¹ï¼Œè¯·ä¼˜å…ˆå¤„ç†å…³é”®é—®é¢˜ã€‚\n")
        elif warning_count > 0:
            md.append(f"- å½“å‰æ— å…³é”®é—®é¢˜ï¼Œå»ºè®®å…ˆå¤„ç†è­¦å‘Šé—®é¢˜ {warning_count} é¡¹ã€‚\n")
        else:
            md.append("- å½“å‰æ— å…³é”®/è­¦å‘Šé—®é¢˜ï¼Œå¯æŒ‰éœ€å¤„ç†ä¿¡æ¯çº§å»ºè®®ã€‚\n")

    # Errors and Warnings
    errors = data.get('errors', [])
    warnings = data.get('warnings', [])

    if errors or warnings:
        md.append("\n## âš ï¸ åˆ†æè¿‡ç¨‹ä¸­çš„é—®é¢˜\n")
        if errors:
            md.append("\n### é”™è¯¯\n")
            for error in errors:
                md.append(f"- âŒ {error}\n")
        if warnings:
            md.append("\n### è­¦å‘Š\n")
            for warning in warnings:
                md.append(f"- âš ï¸ {warning}\n")

    # Footer
    md.append("\n---\n")
    md.append("*æŠ¥å‘Šç”± Web Region & Audience Analyzer ç”Ÿæˆ*\n")

    return ''.join(md)


def main():
    if len(sys.argv) < 2:
        print("Usage: python generate_markdown_report.py <json_file> [output_file]")
        sys.exit(1)

    json_file = sys.argv[1]
    output_file = sys.argv[2] if len(sys.argv) > 2 else None

    with open(json_file, 'r', encoding='utf-8') as f:
        data = json.load(f)

    markdown = generate_markdown_report(data)

    if output_file:
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(markdown)
        print(f"Markdown report saved to: {output_file}")
    else:
        print(markdown)


if __name__ == '__main__':
    main()
